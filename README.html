<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.1.0/github-markdown.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="replication-kairosis">Replication-Kairosis</h1>
<p>Replication package for <strong>“Kairosis: A method for dynamical
probability forecast aggregation informed by Bayesian change point
detection”</strong></p>
<h2 id="readme---reproducibility-package">README - Reproducibility
Package</h2>
<h3 id="package-overview">1. Package Overview</h3>
<p>This repository provides all necessary files to reproduce the results
presented in the paper. The reproducibility package follows two distinct
workflows:</p>
<ol type="1">
<li><strong>Reproducibility of Results (Forecast Computation &amp;
Evaluation) – The Required Step</strong>
<ul>
<li>A Jupyter Notebook (<code>.ipynb</code>) that runs the full forecast
computation and evaluation, producing all plots, figures, and tables in
the paper.<br />
</li>
<li>This workflow <strong>does not omit any calculations</strong>—it
performs the necessary steps to generate results from preprocessed data
files, avoiding unnecessary intermediary recomputation.<br />
</li>
<li>Running this notebook is <strong>the only required step</strong> for
reproducing the results.</li>
</ul></li>
<li><strong>(Optional Verification Only) - Intermediary Computation
Steps and Appendices</strong>
<ul>
<li><p>This branch contains the intermediary processing steps and
appendix materials that transform raw data into a format suitable for
analysis and visualization:</p>
<pre><code>raw data → .py scripts → JSON files → .py scripts → CSV files</code></pre></li>
<li><p>These steps are included <strong>purely for verification
purposes</strong>. They are computationally expensive and <strong>not
required</strong> for reproducing the results in the paper.<br />
</p></li>
<li><p>A keen reader or someone with substantial computing resources
<strong>may choose to rerun these steps</strong>, but this is entirely
optional.<br />
</p></li>
<li><p>A separate <strong>R-based demonstration</strong> is included in
<code>/appendix2</code>. This section is also <strong>not
required</strong> for reproducing the main results but provides an
alternative perspective for those interested in additional
methodological insights. The R scripts here are for demonstration only
and do not impact the core analysis pipeline.</p></li>
</ul></li>
</ol>
<h3 id="running-the-reproducibility-check">2. Running the
Reproducibility Check</h3>
<ul>
<li><strong>To generate all results and plots as presented in the
paper</strong>, simply run <code>Reproducibility_Packet.ipynb</code>.
This notebook fully computes forecasts and scores them using
preprocessed data. The process completes in <strong>a few
minutes</strong> on a standard machine.<br />
</li>
<li><strong>All other computations are completely optional and provided
for verification only.</strong> If you wish to regenerate the
intermediary data files, you can manually run the full pipeline, but be
aware:
<ul>
<li>Running the <strong>full pipeline</strong> requires substantial
computational resources. A full parameter search alone may take
<strong>12+ hours</strong>, while other steps require <strong>2-6
hours</strong>.<br />
</li>
<li>The computations were originally performed on the <strong>University
of York central Linux server</strong> due to high memory requirements.
Running the full process on a personal laptop or desktop <strong>is not
recommended</strong> due to memory constraints and excessive
runtime.</li>
</ul></li>
</ul>
<h3 id="repository-structure">3. Repository Structure</h3>
<pre><code>/IJF_REPRODUCIBILITY_PACKET
│── /__pycache__         # Cached Python modules
│── /figures_data        # Data for figures in main reproducibility notebook
│── /intermediary        # Intermediate computations and verification
│   │── /appendix_b      # Appendix B scripts and data
│   │   │── /forecasts   # Forecast output files
│   │   │── /non_probability_questions  # Additional question datasets
│   │   │── appendix_b_forecasts.py
│   │   │── appendix_b_likelihoods.json
│   │   │── appendix_b_likelihoods.py
│   │── /appendix_c      # Appendix C scripts and data
│   │   │── grid_search_results.csv
│   │   │── grid_search.py
│   │   │── qids.csv # id verification
│── /probability_forecasts  # Probability forecast scripts and results
│   │── log_marginal_likelihood_probabilities.py
│   │── log_marginal_likelihoods_probabilities.json
│   │── probability_forecasts.py
│   │── qids.csv # id verification
│── /questions           # Raw forecast data
│── /table_1_forecasts   # Data for Table 1 in main reproducibility notebook
│── likelihoods.py       # Likelihood functions
│── cleaning.py          # ata cleaning functionsD
│── environment.yml      # Conda environment setup
│── README.md            # This file
│── Reproducibility_Packet.ipynb  # Main reproducibility notebook
│── requirements.txt     # List of dependencies</code></pre>
<h3 id="computing-environment">4. Computing Environment</h3>
<ul>
<li><strong>OS:</strong> Windows 11<br />
</li>
<li><strong>Python Version:</strong> 3.11.5<br />
</li>
<li><strong>Dependencies:</strong> Install with
<code>pip install -r requirements.txt</code> or
<code>conda env create -f environment.yml</code><br />
</li>
<li><strong>Package Dependencies:</strong> Most dependencies are
standard Python libraries commonly used for scientific computing and
data analysis. The included <code>requirements.txt</code> and
<code>environment.yml</code> files are provided for completeness.</li>
</ul>
<h3 id="data-information">5. Data Information</h3>
<ul>
<li><strong>Format:</strong> CSV, JSON<br />
</li>
<li><strong>Processing:</strong> Includes data cleaning and
transformation. Preprocessed files are stored in
<code>/data</code>.</li>
</ul>
<h3 id="optional-running-specific-components">6. <strong>Optional:
Running Specific Components</strong></h3>
<h5 id="a-appendix-b---forecasts-likelihoods"><strong>(a) Appendix B -
Forecasts &amp; Likelihoods</strong></h5>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> intermediary/appendix_b/appendix_b_likelihoods.py  <span class="co"># Creates JSON likelihood data</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> intermediary/appendix_b/appendix_b_forecasts.py  <span class="co"># Generates forecast CSV files from JSON Likelihood</span></span></code></pre></div>
<h5 id="b-appendix-c---grid-search-qids"><strong>(b) Appendix C - Grid
Search &amp; QIDS</strong></h5>
<div class="sourceCode" id="cb4"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> intermediary/appendix_c/grid_search.py  <span class="co"># Generates grid search results CSV</span></span></code></pre></div>
<h5 id="c-probability-forecasts"><strong>(c) Probability
Forecasts</strong></h5>
<div class="sourceCode" id="cb5"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> probability_forecasts/log_marginal_likelihood_probabilities.py  <span class="co"># Creates JSON likelihood data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> probability_forecasts/probability_forecasts.py  <span class="co"># Generates forecast CSV files from JSON Likelihood</span></span></code></pre></div>
<ul>
<li>Outputs (tables, figures) are found in figures_data.</li>
</ul>
<h3 id="hardware-runtime">7. Hardware &amp; Runtime</h3>
<h4 id="for-forecast-aggregating-scoring-evaluation"><strong>For
Forecast Aggregating, Scoring &amp; Evaluation</strong></h4>
<ul>
<li><strong>Estimated Time:</strong> <strong>A few minutes</strong> on a
standard laptop.<br />
</li>
<li><strong>Requirements:</strong> No special hardware needed.</li>
</ul>
<h4 id="for-full-intermediary-data-regeneration-optional"><strong>For
Full Intermediary Data Regeneration (Optional)</strong></h4>
<ul>
<li><strong>Estimated Time:</strong> <strong>12+ hours</strong> for
parameter search, <strong>2-6 hours</strong> for other processing
steps.<br />
</li>
<li><strong>Hardware Required:</strong> University-grade server
(high-memory system). A standard 16-core CPU, 32GB RAM <strong>will
struggle</strong> with certain steps.</li>
</ul>
<h3 id="additional-notes">8. Additional Notes</h3>
<ul>
<li>Intermediate datasets are in <code>/intermediary</code>.</li>
</ul>
</body>
</html>
